# Base Docker Compose - Shared services (milvus + rag-api)
# Use with an override file for the LLM server:
#   docker compose -f docker-compose.yml -f docker-compose.nemotron.yml up -d
#   docker compose -f docker-compose.yml -f docker-compose.gptoss20b.yml up -d
#
# Or create a symlink for default behavior:
#   ln -sf docker-compose.nemotron.yml docker-compose.override.yml
#   docker compose up -d

services:
  # 1. Milvus Vector DB (Standalone mode with embedded etcd/minio)
  milvus:
    image: milvusdb/milvus:v2.5.10-20250418-5a8c98a2-gpu-arm64
    container_name: vector-db
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - ETCD_USE_EMBED=true
      - ETCD_DATA_DIR=/var/lib/milvus/etcd
      - COMMON_STORAGETYPE=local
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - milvus_data:/var/lib/milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    command: ["milvus", "run", "standalone"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 2. RAG API
  rag-api:
    image: rag-api:latest
    container_name: rag-endpoint
    environment:
      - MILVUS_URL=http://milvus:19530
      - VLLM_URL=http://llm-server:8000/v1
    volumes:
      - ./app:/app
      - /home/devmaster/sop_documents:/documents
    ports:
      - "8080:8080"
    depends_on:
      - llm-server
      - milvus
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  milvus_data:
