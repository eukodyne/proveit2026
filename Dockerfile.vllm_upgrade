FROM nvcr.io/nvidia/vllm:25.12-py3

# Blackwell Environment Setup
ENV TORCH_CUDA_ARCH_LIST="12.0"
ENV VLLM_INSTALL_PUNICA_KERNELS=1
ENV MAX_JOBS=8
ENV UV_BREAK_SYSTEM_PACKAGES=1

USER root

# 1. Direct Download of the CUDA 12.4 runtime library (ARM64)
# We pull just the runtime package and extract the missing libcudart.so.12
RUN apt-get update && apt-get install -y wget binutils && \
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/arm64/cuda-cudart-12-4_12.4.127-1_arm64.deb && \
    ar x cuda-cudart-12-4_12.4.127-1_arm64.deb && \
    tar -xvf data.tar.zst && \
    cp usr/local/cuda-12.4/lib64/libcudart.so.12* /usr/local/lib/ && \
    rm -rf cuda-cudart-12-4* data.tar.zst control.tar.gz debian-binary usr && \
    ldconfig /usr/local/lib

# 2. Re-install vLLM 0.13.0 dependencies
RUN pip install uv --break-system-packages
RUN uv pip install --system --break-system-packages --no-cache-dir vllm==0.13.0 --no-deps
RUN uv pip install --system --break-system-packages "fastsafetensors>=0.1.0" "flashinfer-python" "xgrammar"

# 3. VERIFICATION: This MUST pass during the build process
RUN python3 -c "import vllm; print('SUCCESS: vLLM successfully imported and linked to libcudart.so.12')"

ENTRYPOINT ["python3", "-m vllm.entrypoints.openai.api_server"]