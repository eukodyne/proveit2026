# Use the official NVIDIA vLLM base
FROM nvcr.io/nvidia/vllm:25.12-py3

# --- FORUM GUIDED ENV VARS FOR BLACKWELL ---
ENV TORCH_CUDA_ARCH_LIST="12.0"
ENV TRITON_PTXAS_PATH="/usr/local/cuda/bin/ptxas"
ENV VLLM_INSTALL_PUNICA_KERNELS=1
ENV MAX_JOBS=12
ENV UV_BREAK_SYSTEM_PACKAGES=1

USER root

# 1. Add NVIDIA Repository for Ubuntu 24.04 (SBSA/ARM64)
RUN apt-get update && apt-get install -y wget gnupg2 && \
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/sbsa/cuda-keyring_1.1-1_all.deb && \
    dpkg -i cuda-keyring_1.1-1_all.deb && \
    apt-get update

# 2. Install CUDA 13.1 Dev Headers (Fixes 'cusparse.h' missing)
RUN apt-get install -y \
    cuda-cusparse-dev-13-1 \
    cuda-cublas-dev-13-1 \
    cuda-cufft-dev-13-1 \
    cuda-curand-dev-13-1 \
    cuda-nvrtc-dev-13-1 \
    cuda-nvml-dev-13-1 \
    python3.12-dev cmake git ccache ninja-build && \
    rm -rf /var/lib/apt/lists/*

# 3. Setup Build Tools
RUN pip install uv --break-system-packages && \
    uv pip install --system --break-system-packages "setuptools>=69.0" "setuptools_scm>=8.0" "wheel" "ninja"

# 4. Build vLLM 0.13.0 from Source
# Using native compilation ensures binary compatibility with NVIDIA's PyTorch
RUN git clone --depth 1 --branch v0.13.0 https://github.com/vllm-project/vllm.git /opt/vllm_src && \
    cd /opt/vllm_src && \
    uv pip install --system --break-system-packages \
    "ijson" "partial-json-parser" "py-cpuinfo" "xgrammar" "flashinfer-python" && \
    python3 setup.py install

# 5. Verification
RUN python3 -c "import vllm; print('SUCCESS: vLLM 0.13.0 is built for Blackwell SM120.')"

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]