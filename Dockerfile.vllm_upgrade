# 1. Use a raw CUDA Development image (Ubuntu 24.04 ARM64)
FROM nvidia/cuda:12.6.3-devel-ubuntu24.04

# --- BLACKWELL & BUILD SETTINGS ---
ENV TORCH_CUDA_ARCH_LIST="12.0"
ENV MAX_JOBS=12
ENV DEBIAN_FRONTEND=noninteractive

USER root

# 2. Install Python 3.12 and build essentials
RUN apt-get update && apt-get install -y \
    python3.12 python3.12-dev python3-pip \
    cmake git ccache ninja-build wget gnupg2 \
    && rm -rf /var/lib/apt/lists/*

# 3. Setup Python environment
RUN ln -sf /usr/bin/python3.12 /usr/bin/python3 && \
    ln -sf /usr/bin/python3.12 /usr/bin/python && \
    python3 -m pip install --upgrade pip setuptools wheel

# 4. Install Torch (Must be a version that supports Blackwell/CUDA 12.6+)
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 5. Build vLLM 0.13.0 from Source
RUN git clone --depth 1 --branch v0.13.0 https://github.com/vllm-project/vllm.git /opt/vllm_src && \
    cd /opt/vllm_src && \
    # Install dependencies
    pip install -r requirements.txt && \
    pip install "flashinfer-python" "fastsafetensors>=0.1.1" && \
    # The actual build
    python3 setup.py install

# 6. CRITICAL VERIFICATION: This will fail the build if the version is wrong
RUN ACTUAL_VERSION=$(python3 -c "import vllm; print(vllm.__version__)") && \
    echo "Detected Version: $ACTUAL_VERSION" && \
    if [ "$ACTUAL_VERSION" != "0.13.0" ]; then echo "VERSION MISMATCH! Got $ACTUAL_VERSION"; exit 1; fi

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]