# 1. Use the stable Blackwell-compatible production image
FROM nvidia/cuda:12.8.0-devel-ubuntu24.04

# --- BLACKWELL (SM120) & BUILD STABILITY SETTINGS ---
ENV TORCH_CUDA_ARCH_LIST="12.0"
ENV VLLM_TARGET_DEVICE="cuda"
# Force the version to bypass the 'Unknown runtime environment' error
ENV VLLM_VERSION_OVERRIDE="0.13.0"
ENV SETUPTOOLS_SCM_PRETEND_VERSION="0.13.0"
# Shared RAM safety: Lower jobs to 2 to prevent the 'dnnl' linking crash
ENV MAX_JOBS=2
ENV DEBIAN_FRONTEND=noninteractive

USER root

# 2. Install ARM64 build essentials
RUN apt-get update && apt-get install -y \
    python3.12 python3.12-dev python3-pip \
    cmake git ccache ninja-build wget gnupg2 \
    libgoogle-perftools-dev numactl \
    && rm -rf /var/lib/apt/lists/*

# 3. Setup Python 3.12
RUN ln -sf /usr/bin/python3.12 /usr/bin/python3 && \
    python3 -m pip install --upgrade pip setuptools wheel setuptools-scm --break-system-packages --ignore-installed

# 4. Install Blackwell-ready Torch and NumPy
# Pre-installing NumPy fixes the Torch 'Failed to initialize NumPy' warning
RUN pip install "numpy<2.0" torch torchvision torchaudio --break-system-packages

# 5. Build vLLM 0.13.0
# Note: We still use --depth 1 for speed, but the ENV variables above fix the error it caused
RUN git clone --depth 1 --branch v0.13.0 https://github.com/vllm-project/vllm.git /opt/vllm_src && \
    cd /opt/vllm_src && \
    # Install specific Blackwell dependencies
    pip install "flashinfer-python" "fastsafetensors>=0.1.1" --break-system-packages && \
    # The build: We use --no-build-isolation to use the packages we just installed
    pip install . --verbose --break-system-packages --no-build-isolation

# 6. VERSION GUARD
RUN python3 -c "import vllm; print(f'VERIFIED: vLLM {vllm.__version__} is ready for SM120.')"

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]